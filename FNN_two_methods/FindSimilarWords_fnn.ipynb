{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json_lines as jls\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from jedi.api.refactoring import inline\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_file:  contents_small.jl\n",
      "weight_dir:  Weights_fnn\n"
     ]
    }
   ],
   "source": [
    "TRAIN = \" \"\n",
    "if TRAIN == \"test\":\n",
    "    train_file = 'contents_test.jl'\n",
    "    weight_dir = 'Weights_fnn_small'\n",
    "else:\n",
    "    train_file = 'contents_small.jl'\n",
    "    weight_dir = 'Weights_fnn'\n",
    "print(\"train_file: \", train_file)\n",
    "print(\"weight_dir: \", weight_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {}\n",
    "word_to_id = np.load(f'{weight_dir}/dict_fnn.npy',allow_pickle=True).item()\n",
    "id_to_word = {}\n",
    "for key in word_to_id:\n",
    "    id_to_word[word_to_id[key]] = key\n",
    "print(len(word_to_id))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "embedding_num = 10\n",
    "model = {}\n",
    "model[\"w1\"] = np.load(f'{weight_dir}/weight_1_20.npy')\n",
    "model[\"w2\"] = np.load(f'{weight_dir}/weight_2_20.npy')\n",
    "def get_range(*iterables):\n",
    "    for iterable in iterables:\n",
    "        yield from iterable\n",
    "\n",
    "def one_hot_encode(id, vocab_size, s=False):\n",
    "    res = [0] * vocab_size\n",
    "\n",
    "    res[id] = 1\n",
    "    if s==True:\n",
    "        print(len(res))\n",
    "    return res\n",
    "def generate_test_data(tokens, word_to_id):\n",
    "    X = []\n",
    "    for i in range(0, 4):\n",
    "        X.append(one_hot_encode(word_to_id[tokens[i].lower()],\n",
    "                                len(word_to_id)))\n",
    "    return np.asarray(X)\n",
    "def softmax(X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        exp = np.exp(x - np.max(x))\n",
    "        res.append(exp / exp.sum())\n",
    "    return res\n",
    "def cross_entropy(z, y):\n",
    "    for i, array in enumerate(z):\n",
    "        z[i] = array + len(array)*[0.0001]\n",
    "    return - np.sum(np.log(z) * y)\n",
    "def get_aver_matrix(k1):\n",
    "    AVER = np.array([[0]*k1*4]*k1)\n",
    "    TEMP = []\n",
    "    for i, row in enumerate(AVER):\n",
    "        # print(i)\n",
    "        child_TEMP = list(row)\n",
    "        child_TEMP[4*i] = 0.25\n",
    "        child_TEMP[4*i+1] = 0.25\n",
    "        child_TEMP[4*i+2] = 0.25\n",
    "        child_TEMP[4*i+3] = 0.25\n",
    "        TEMP.append(np.array(child_TEMP))\n",
    "    AVER = np.array(TEMP)\n",
    "    return AVER\n",
    "def forward(model, X, return_cache=True):\n",
    "    cache = {}\n",
    "    cache[\"a1\"] = X @ model[\"w1\"]\n",
    "    k1 = int(X.shape[0]/4)\n",
    "    AVER = get_aver_matrix(k1)\n",
    "    cache[\"b\"] = AVER @ cache[\"a1\"]\n",
    "    cache[\"a2\"] = cache[\"b\"] @ model[\"w2\"]\n",
    "    cache[\"z\"] = softmax(cache[\"a2\"])\n",
    "    if not return_cache:\n",
    "        print(\"W1.shape: \",model[\"w1\"].shape)\n",
    "        print(\"A1.shape: \",cache[\"a1\"].shape)\n",
    "        print(\"B.shape: \",cache[\"b\"].shape)\n",
    "        print(\"A2.shape: \",cache[\"a2\"].shape)\n",
    "        print(type(cache[\"z\"]))\n",
    "        return cache[\"z\"]\n",
    "    return cache\n",
    "def generate_test_data(tokens, word_to_id):\n",
    "    X = []\n",
    "    for i in range(0, 4):\n",
    "        X.append(one_hot_encode(word_to_id[tokens[i].lower()],\n",
    "                                len(word_to_id)))\n",
    "    return np.asarray(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn shape (4, 1001)\n",
      "W1.shape:  (1001, 10)\n",
      "A1.shape:  (4, 10)\n",
      "B.shape:  (1, 10)\n",
      "A2.shape:  (1, 1001)\n",
      "<class 'list'>\n",
      "result shape 1001\n",
      "most possible:  600 0.024744032272691258\n",
      "doses\n"
     ]
    }
   ],
   "source": [
    "learning = generate_test_data([\"rich\",\"cultural\",\"and\",\"natural\"], word_to_id)\n",
    "learn = np.array(learning)\n",
    "print(\"learn shape\", learn.shape)\n",
    "result = forward(model, learn, return_cache=False)[0]\n",
    "print(\"result shape\", result.__len__())\n",
    "id = 0\n",
    "temp = 0\n",
    "for i, prob in enumerate(result):\n",
    "    if temp == 0:\n",
    "        temp = prob\n",
    "        id = i\n",
    "    elif prob > temp:\n",
    "        temp = prob\n",
    "        id = i\n",
    "print(\"most possible: \",id,result[id])\n",
    "print(id_to_word[id])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 10)\n"
     ]
    }
   ],
   "source": [
    "Vectors = np.load(f'{weight_dir}/weight_1_20.npy')\n",
    "print(Vectors.shape)\n",
    "def ed(m, n):\n",
    " return np.sqrt(np.sum((m - n) ** 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chew', 'inflation', 'heritage', 'ethics', 'reinforced', 'adults', 'together', 'four', 'continued', 'relations', 'household']\n",
      "['rich', 'means', 'inflation', 'under', 'indicating', 'event', 'continued', 'adults', 'upali', 'risk', 'away']\n",
      "['become', 'seen', 'beverages', 'grains', 'region', 'rhythmic', 'attended', 'promoting', 'aratchilage', 'sure', 'reduction']\n",
      "['southern', 'movement', 'due', 'thursday', 'resources', 'rose', 'indicating', 'matshidiso', 'aratchilage', 'after', 'within']\n",
      "['s', 'inflation', 'need', 'seen', 'beverages', 'benefit', 'e', 'continued', 'into', 'drought', 'reinforced']\n",
      "['s', 'inflation', 'need', 'seen', 'beverages', 'benefit', 'e', 'continued', 'into', 'drought', 'reinforced']\n",
      "['express', 'inflation', 'need', 'away', 'ethics', 'reinforced', 'e', 'adults', 'heritage', 'become', 'after']\n",
      "['expressed', 'into', 'four', 'forward', 'parents', 'beverages', 'sure', 'benefit', 'risk', 'seen', 'had']\n",
      "['southern', 'movement', 'due', 'thursday', 'resources', 'rose', 'indicating', 'matshidiso', 'aratchilage', 'after', 'within']\n",
      "['be', 'beverages', 'seen', 'aratchilage', 'markets', 'partially', 'after', 'sure', 'move', 'had', 'published']\n",
      "['government', 'resources', 'heritage', 'inflation', 'due', 'matshidiso', 'rose', 'indicating', 'thursday', 'profit', 'parents']\n",
      "['more', 'shillings', 'after', 'discuss', 'mass', 'within', 'middle', 'seen', 'markets', 'table', 'indicating']\n",
      "['she', 'indicating', 'million', 'shillings', 'concentrate', 'means', 'under', 'our', 'reduction', 'ethiopia', 'after']\n",
      "['winter', 'inflation', 'readiness', 'heritage', 'indicating', 'due', 'adults', 'after', 'resources', 'become', 'thursday']\n",
      "['interpret', 'inflation', 'profit', 'resources', 'need', 'well', 'due', 'indicating', 'around', 'benefit', 'further']\n",
      "['interpret', 'inflation', 'profit', 'resources', 'need', 'well', 'due', 'indicating', 'around', 'benefit', 'further']\n",
      "['olympics', 'aratchilage', 'parents', 'well', 'need', 'into', 'seen', 'resources', 'beverages', 'respective', 'readiness']\n",
      "['athletes', 'aratchilage', 'within', 'movement', 'transaction', 'mass', 'due', 'resources', 'matshidiso', 'thursday', 'profit']\n",
      "['parliament', 'beverages', 'seen', 'after', 'markets', 'into', 'risk', 'week', 'shillings', 'increased', 'co']\n",
      "['interest', 'resources', 'heritage', 'co', 'indicating', 'due', 'become', 'months', 'sunday', 'indicated', 'areas']\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    words = []\n",
    "    ID = int(np.random.uniform(0,169))\n",
    "    # print(\"WORD: \",id_to_word[ID])\n",
    "    words.append(id_to_word[ID])\n",
    "    VEC = Vectors[ID]\n",
    "    dist_to_id = {}\n",
    "    dists = []\n",
    "    for i, vector in enumerate(Vectors):\n",
    "        dist = ed(vector,VEC)\n",
    "        dist_to_id[dist]=i\n",
    "        dists.append(dist)\n",
    "    dists.sort(reverse=True)\n",
    "    for i, dist in enumerate(dists):\n",
    "        if i == 10:\n",
    "            break\n",
    "        words.append(id_to_word[dist_to_id[dist]])\n",
    "    print(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}